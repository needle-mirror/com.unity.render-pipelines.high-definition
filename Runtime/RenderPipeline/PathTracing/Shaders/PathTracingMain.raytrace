// We need N bounces given that we want to support complex light paths
#pragma max_recursion_depth 11

// HDRP include
#define SHADER_TARGET 50

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"

// Ray tracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingIntersection.hlsl"

// Path tracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/PathTracing/Shaders/PathTracingSampling.hlsl"

// Input(s)
float4x4 _PixelCoordToViewDirWS;

// Output(s)
RWTexture2D<float4> _CameraColorTextureRW;
RWTexture2D<float4> _AccumulatedFrameTexture;

void AddConvergenceCue(uint2 pixelCoord, uint sampleCount, inout float3 color)
{
    uint width, height;
    _CameraColorTextureRW.GetDimensions(width, height);

    // Change color only in a region corresponding to a progress bar, on the bottom 1% of the screen
    if (pixelCoord.y < 0.01 * height && (float)pixelCoord.x / width <= (float)sampleCount / (_RaytracingNumSamples - 1))
    {
        float lum = Luminance(color);

        if (lum > 1.0)
        {
            color /= lum;
            lum = 1.0;
        }

        // Make dark color brighter, and vice versa
        color += lum > 0.5 ? -0.5 * lum : 0.05 + 0.5 * lum;
    }
}

[shader("miss")]
void Miss(inout RayIntersection rayIntersection : SV_RayPayload)
{
    // Grab depth information
    uint currentDepth = _RaytracingMaxRecursion - rayIntersection.remainingDepth;

    rayIntersection.color = !currentDepth || currentDepth >= _RaytracingMinRecursion ?
        SAMPLE_TEXTURECUBE_ARRAY_LOD(_SkyTexture, s_trilinear_clamp_sampler, WorldRayDirection(), 0.0f, 0) : 0.0;
}

[shader("raygeneration")]
void RayGen()
{
    uint2 LaunchIndex = DispatchRaysIndex();
    uint2 LaunchDim = DispatchRaysDimensions();

    // Pixel coordinate of the current pixel
    uint2 currentPixelCoord = uint2(LaunchIndex.x, LaunchIndex.y);

    // Get the current sample count
    uint sampleCount = _AccumulatedFrameTexture[currentPixelCoord].w;

    // Grab motion blur information (FIXME: should be replaced by something else notifying of a change in the scene)
    float2 velocity;
    DecodeMotionVector(LOAD_TEXTURE2D_X(_CameraMotionVectorsTexture, currentPixelCoord), velocity);

    // Have we reached max sampling?
    if (sampleCount >= _RaytracingNumSamples && !any(velocity))
    {
        _CameraColorTextureRW[currentPixelCoord] = float4(_AccumulatedFrameTexture[currentPixelCoord].xyz * GetCurrentExposureMultiplier(), 1.0);
        return;
    }

    // Get jittered pixel coordinates
    float3 jitteredPixelCoord = float3(currentPixelCoord, 1.0);
    jitteredPixelCoord.x += GetSample(currentPixelCoord, _RaytracingFrameIndex, 254);
    jitteredPixelCoord.y += GetSample(currentPixelCoord, _RaytracingFrameIndex, 255);

    // Compute the ray direction, from those coordinates
    float3 directionWS = -normalize(mul(jitteredPixelCoord, (float3x3)_PixelCoordToViewDirWS));

    // Create the ray descriptor for this pixel
    RayDesc rayDescriptor;
    rayDescriptor.Origin = _WorldSpaceCameraPos;
    rayDescriptor.Direction = directionWS;
    rayDescriptor.TMin = _RaytracingCameraNearPlane;
    rayDescriptor.TMax = FLT_INF;

    // Create and init the RayIntersection structure for this
    RayIntersection rayIntersection;
    rayIntersection.color = 1.0;
    rayIntersection.remainingDepth = _RaytracingMaxRecursion;
    rayIntersection.pixelCoord = currentPixelCoord;
    rayIntersection.maxRoughness = 0.001;
    rayIntersection.rayCount = sampleCount;

    // In order to achieve filtering for the textures, we need to compute the spread angle of the pixel
    rayIntersection.cone.spreadAngle = _RaytracingPixelSpreadAngle;
    rayIntersection.cone.width = 0.0f;

    // Evaluate the ray intersection
    TraceRay(_RaytracingAccelerationStructure, RAY_FLAG_CULL_BACK_FACING_TRIANGLES | RAY_FLAG_FORCE_OPAQUE, RAYTRACINGRENDERERFLAG_PATH_TRACING, 0, 1, 0, rayDescriptor, rayIntersection);

    // FIXME: should be based on another criterion than velocity
    // Accumulate the result
    if (any(velocity))
    {
        sampleCount = 1; // Reset sample count
    }
    else
    {
        sampleCount++;
        rayIntersection.color = (_AccumulatedFrameTexture[currentPixelCoord].xyz * (sampleCount - 1) + rayIntersection.color * GetInverseCurrentExposureMultiplier()) / sampleCount;
    }
    _AccumulatedFrameTexture[currentPixelCoord] = float4(rayIntersection.color, sampleCount);

    // Add a little convergence cue to our result (FIXME: definitely not the right way to do it!!)
    AddConvergenceCue(currentPixelCoord, sampleCount, rayIntersection.color);

    _CameraColorTextureRW[currentPixelCoord] = float4(rayIntersection.color * GetCurrentExposureMultiplier(), 1.0);
}

[shader("closesthit")]
void ClosestHit(inout RayIntersection rayIntersection : SV_RayPayload, AttributeData attributeData : SV_IntersectionAttributes)
{
    rayIntersection.color = float3(1.0, 0.0, 0.5);
}
